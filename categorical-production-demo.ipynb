{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8642f315-93d3-4406-8f4a-0d2527dfe2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Imbalanced-learn import\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax, AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.regularizers import l1, l2, L1L2\n",
    "\n",
    "# Optuna import\n",
    "import optuna\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to save the scaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "397e3b13-5869-4569-94c1-1c662c2d986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult     460\n",
      "senior    306\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(5390) \n",
    "np.random.seed(5390)\n",
    "tf.random.set_seed(5390)\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 10),\n",
    "    'senior': (10, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f7e4f-740d-4b02-b607-a1250fe976e2",
   "metadata": {},
   "source": [
    "# save demo rows to external csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0d81d073-1297-4234-9573-d47d6e04cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows corresponding to the specified cat_id values\n",
    "selected_cat_ids = ['108A', '109A', '037A']\n",
    "demo_samples = dataframe[dataframe['cat_id'].isin(selected_cat_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "12a12fcd-e5fc-4ab4-a13d-949a94708d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>gender</th>\n",
       "      <th>target</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2832.0293</td>\n",
       "      <td>-1224.3556</td>\n",
       "      <td>-3104.6710</td>\n",
       "      <td>135.26700</td>\n",
       "      <td>199.70366</td>\n",
       "      <td>4972.9290</td>\n",
       "      <td>-1742.1462</td>\n",
       "      <td>-1933.5850</td>\n",
       "      <td>6134.8670</td>\n",
       "      <td>2059.8123</td>\n",
       "      <td>...</td>\n",
       "      <td>2552.5480</td>\n",
       "      <td>-474.32940</td>\n",
       "      <td>-2933.9365</td>\n",
       "      <td>3395.8880</td>\n",
       "      <td>-6107.7456</td>\n",
       "      <td>-1061.96420</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109A</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2687.3303</td>\n",
       "      <td>-1167.7533</td>\n",
       "      <td>-2927.5361</td>\n",
       "      <td>133.91333</td>\n",
       "      <td>176.22916</td>\n",
       "      <td>4708.4370</td>\n",
       "      <td>-1666.4711</td>\n",
       "      <td>-1813.6730</td>\n",
       "      <td>5830.6094</td>\n",
       "      <td>1962.3767</td>\n",
       "      <td>...</td>\n",
       "      <td>2429.6272</td>\n",
       "      <td>-439.15106</td>\n",
       "      <td>-2776.0312</td>\n",
       "      <td>3213.3528</td>\n",
       "      <td>-5826.5090</td>\n",
       "      <td>-1019.60443</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109A</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2742.9766</td>\n",
       "      <td>-1191.6954</td>\n",
       "      <td>-2980.1370</td>\n",
       "      <td>152.56021</td>\n",
       "      <td>226.44548</td>\n",
       "      <td>4841.6235</td>\n",
       "      <td>-1725.6976</td>\n",
       "      <td>-1820.9745</td>\n",
       "      <td>5985.0947</td>\n",
       "      <td>2013.3196</td>\n",
       "      <td>...</td>\n",
       "      <td>2470.2888</td>\n",
       "      <td>-470.13130</td>\n",
       "      <td>-2825.3770</td>\n",
       "      <td>3296.9670</td>\n",
       "      <td>-5967.8623</td>\n",
       "      <td>-1079.46000</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109A</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>2869.8135</td>\n",
       "      <td>-1226.8926</td>\n",
       "      <td>-3099.9812</td>\n",
       "      <td>133.81638</td>\n",
       "      <td>207.58218</td>\n",
       "      <td>5034.4430</td>\n",
       "      <td>-1772.9384</td>\n",
       "      <td>-1923.5074</td>\n",
       "      <td>6199.7950</td>\n",
       "      <td>2082.9504</td>\n",
       "      <td>...</td>\n",
       "      <td>2581.1968</td>\n",
       "      <td>-515.49690</td>\n",
       "      <td>-2954.4731</td>\n",
       "      <td>3453.4902</td>\n",
       "      <td>-6172.2075</td>\n",
       "      <td>-1075.68760</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109A</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3137.8435</td>\n",
       "      <td>-1348.4828</td>\n",
       "      <td>-3411.0800</td>\n",
       "      <td>130.62189</td>\n",
       "      <td>211.46841</td>\n",
       "      <td>5463.0680</td>\n",
       "      <td>-1941.1052</td>\n",
       "      <td>-2126.2073</td>\n",
       "      <td>6714.9062</td>\n",
       "      <td>2247.8354</td>\n",
       "      <td>...</td>\n",
       "      <td>2828.8767</td>\n",
       "      <td>-578.98880</td>\n",
       "      <td>-3247.7790</td>\n",
       "      <td>3778.4870</td>\n",
       "      <td>-6727.5615</td>\n",
       "      <td>-1191.70600</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109A</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3867.1643</td>\n",
       "      <td>-1669.0719</td>\n",
       "      <td>-4053.3696</td>\n",
       "      <td>241.06406</td>\n",
       "      <td>302.83722</td>\n",
       "      <td>6505.4146</td>\n",
       "      <td>-2291.9287</td>\n",
       "      <td>-2485.9430</td>\n",
       "      <td>7899.7030</td>\n",
       "      <td>2651.6104</td>\n",
       "      <td>...</td>\n",
       "      <td>3219.7515</td>\n",
       "      <td>-564.68640</td>\n",
       "      <td>-3733.3735</td>\n",
       "      <td>4508.9165</td>\n",
       "      <td>-8047.7256</td>\n",
       "      <td>-1539.71840</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108A</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>3251.6430</td>\n",
       "      <td>-1394.3860</td>\n",
       "      <td>-3463.1084</td>\n",
       "      <td>230.08203</td>\n",
       "      <td>217.76968</td>\n",
       "      <td>5463.2530</td>\n",
       "      <td>-1921.9489</td>\n",
       "      <td>-2112.7670</td>\n",
       "      <td>6662.2188</td>\n",
       "      <td>2243.1538</td>\n",
       "      <td>...</td>\n",
       "      <td>2744.6404</td>\n",
       "      <td>-462.93610</td>\n",
       "      <td>-3175.2788</td>\n",
       "      <td>3814.7240</td>\n",
       "      <td>-6818.2993</td>\n",
       "      <td>-1289.64870</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108A</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2879.9160</td>\n",
       "      <td>-1229.9530</td>\n",
       "      <td>-3122.3530</td>\n",
       "      <td>141.35180</td>\n",
       "      <td>212.84225</td>\n",
       "      <td>4930.6720</td>\n",
       "      <td>-1748.3600</td>\n",
       "      <td>-1925.1099</td>\n",
       "      <td>6051.9610</td>\n",
       "      <td>2091.0020</td>\n",
       "      <td>...</td>\n",
       "      <td>2524.9436</td>\n",
       "      <td>-509.46540</td>\n",
       "      <td>-2921.8657</td>\n",
       "      <td>3454.4592</td>\n",
       "      <td>-6052.8047</td>\n",
       "      <td>-1120.52040</td>\n",
       "      <td>X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>037A</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>3051.1982</td>\n",
       "      <td>-1305.8528</td>\n",
       "      <td>-3279.6475</td>\n",
       "      <td>122.02283</td>\n",
       "      <td>193.37450</td>\n",
       "      <td>5139.2646</td>\n",
       "      <td>-1826.1930</td>\n",
       "      <td>-2049.3958</td>\n",
       "      <td>6305.3945</td>\n",
       "      <td>2183.4620</td>\n",
       "      <td>...</td>\n",
       "      <td>2658.9524</td>\n",
       "      <td>-549.69130</td>\n",
       "      <td>-3071.2742</td>\n",
       "      <td>3649.5955</td>\n",
       "      <td>-6375.6600</td>\n",
       "      <td>-1163.83980</td>\n",
       "      <td>X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>037A</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>3367.7542</td>\n",
       "      <td>-1415.1522</td>\n",
       "      <td>-3596.3857</td>\n",
       "      <td>144.67197</td>\n",
       "      <td>243.71260</td>\n",
       "      <td>5695.8374</td>\n",
       "      <td>-2012.0200</td>\n",
       "      <td>-2226.8752</td>\n",
       "      <td>6994.3135</td>\n",
       "      <td>2406.5762</td>\n",
       "      <td>...</td>\n",
       "      <td>2922.9407</td>\n",
       "      <td>-602.88360</td>\n",
       "      <td>-3367.2234</td>\n",
       "      <td>3993.3862</td>\n",
       "      <td>-7069.6455</td>\n",
       "      <td>-1335.39890</td>\n",
       "      <td>X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>037A</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>2498.3262</td>\n",
       "      <td>-1052.4727</td>\n",
       "      <td>-2653.8920</td>\n",
       "      <td>110.90628</td>\n",
       "      <td>186.68768</td>\n",
       "      <td>4281.7220</td>\n",
       "      <td>-1544.8362</td>\n",
       "      <td>-1661.8435</td>\n",
       "      <td>5272.6570</td>\n",
       "      <td>1784.1447</td>\n",
       "      <td>...</td>\n",
       "      <td>2154.5686</td>\n",
       "      <td>-421.37674</td>\n",
       "      <td>-2483.4302</td>\n",
       "      <td>2984.2153</td>\n",
       "      <td>-5302.4473</td>\n",
       "      <td>-986.29803</td>\n",
       "      <td>X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>037A</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>2500.6868</td>\n",
       "      <td>-1047.2345</td>\n",
       "      <td>-2656.4927</td>\n",
       "      <td>93.68875</td>\n",
       "      <td>159.70798</td>\n",
       "      <td>4243.1940</td>\n",
       "      <td>-1514.3646</td>\n",
       "      <td>-1688.7804</td>\n",
       "      <td>5225.9727</td>\n",
       "      <td>1771.8201</td>\n",
       "      <td>...</td>\n",
       "      <td>2178.6033</td>\n",
       "      <td>-443.71045</td>\n",
       "      <td>-2491.8884</td>\n",
       "      <td>2979.0862</td>\n",
       "      <td>-5240.8800</td>\n",
       "      <td>-944.70320</td>\n",
       "      <td>X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>037A</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>3284.6416</td>\n",
       "      <td>-1371.1968</td>\n",
       "      <td>-3414.3423</td>\n",
       "      <td>151.45392</td>\n",
       "      <td>252.93144</td>\n",
       "      <td>5480.6280</td>\n",
       "      <td>-1964.4943</td>\n",
       "      <td>-2176.6072</td>\n",
       "      <td>6698.5293</td>\n",
       "      <td>2268.5947</td>\n",
       "      <td>...</td>\n",
       "      <td>2801.8540</td>\n",
       "      <td>-573.87550</td>\n",
       "      <td>-3170.0178</td>\n",
       "      <td>3905.7253</td>\n",
       "      <td>-6786.7793</td>\n",
       "      <td>-1293.54830</td>\n",
       "      <td>X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>037A</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>3310.4907</td>\n",
       "      <td>-1448.4641</td>\n",
       "      <td>-3504.9995</td>\n",
       "      <td>209.27734</td>\n",
       "      <td>254.37192</td>\n",
       "      <td>5639.5757</td>\n",
       "      <td>-1937.9694</td>\n",
       "      <td>-2135.6604</td>\n",
       "      <td>6865.8410</td>\n",
       "      <td>2302.3380</td>\n",
       "      <td>...</td>\n",
       "      <td>2791.3323</td>\n",
       "      <td>-429.82425</td>\n",
       "      <td>-3263.4653</td>\n",
       "      <td>3877.7256</td>\n",
       "      <td>-6970.0034</td>\n",
       "      <td>-1344.60670</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108A</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>3608.8062</td>\n",
       "      <td>-1581.5908</td>\n",
       "      <td>-3858.2456</td>\n",
       "      <td>237.73800</td>\n",
       "      <td>284.46270</td>\n",
       "      <td>6128.4770</td>\n",
       "      <td>-2109.9106</td>\n",
       "      <td>-2314.5550</td>\n",
       "      <td>7428.4893</td>\n",
       "      <td>2504.6475</td>\n",
       "      <td>...</td>\n",
       "      <td>3053.1516</td>\n",
       "      <td>-490.29477</td>\n",
       "      <td>-3579.6978</td>\n",
       "      <td>4251.9960</td>\n",
       "      <td>-7558.4863</td>\n",
       "      <td>-1451.14070</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108A</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>3312.9326</td>\n",
       "      <td>-1411.2800</td>\n",
       "      <td>-3540.8320</td>\n",
       "      <td>206.37589</td>\n",
       "      <td>271.44140</td>\n",
       "      <td>5713.6140</td>\n",
       "      <td>-1974.0682</td>\n",
       "      <td>-2161.9531</td>\n",
       "      <td>6949.9170</td>\n",
       "      <td>2359.5370</td>\n",
       "      <td>...</td>\n",
       "      <td>2851.3274</td>\n",
       "      <td>-450.25323</td>\n",
       "      <td>-3287.7632</td>\n",
       "      <td>3861.2432</td>\n",
       "      <td>-7106.4634</td>\n",
       "      <td>-1344.08020</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108A</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>4069.3052</td>\n",
       "      <td>-1754.0530</td>\n",
       "      <td>-4254.2183</td>\n",
       "      <td>256.76642</td>\n",
       "      <td>278.84686</td>\n",
       "      <td>6848.9440</td>\n",
       "      <td>-2382.5837</td>\n",
       "      <td>-2604.7615</td>\n",
       "      <td>8368.1380</td>\n",
       "      <td>2818.7363</td>\n",
       "      <td>...</td>\n",
       "      <td>3391.4788</td>\n",
       "      <td>-549.24050</td>\n",
       "      <td>-3919.2540</td>\n",
       "      <td>4713.3690</td>\n",
       "      <td>-8497.2140</td>\n",
       "      <td>-1590.58420</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108A</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2823.5095</td>\n",
       "      <td>-1205.9938</td>\n",
       "      <td>-3059.5461</td>\n",
       "      <td>134.26843</td>\n",
       "      <td>213.33296</td>\n",
       "      <td>4943.9690</td>\n",
       "      <td>-1753.3990</td>\n",
       "      <td>-1877.6344</td>\n",
       "      <td>6086.7715</td>\n",
       "      <td>2017.0862</td>\n",
       "      <td>...</td>\n",
       "      <td>2552.5042</td>\n",
       "      <td>-459.96432</td>\n",
       "      <td>-2875.1280</td>\n",
       "      <td>3367.5002</td>\n",
       "      <td>-6091.3430</td>\n",
       "      <td>-1054.48690</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109A</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5  \\\n",
       "152  2832.0293 -1224.3556 -3104.6710  135.26700  199.70366  4972.9290   \n",
       "201  2687.3303 -1167.7533 -2927.5361  133.91333  176.22916  4708.4370   \n",
       "284  2742.9766 -1191.6954 -2980.1370  152.56021  226.44548  4841.6235   \n",
       "469  2869.8135 -1226.8926 -3099.9812  133.81638  207.58218  5034.4430   \n",
       "470  3137.8435 -1348.4828 -3411.0800  130.62189  211.46841  5463.0680   \n",
       "494  3867.1643 -1669.0719 -4053.3696  241.06406  302.83722  6505.4146   \n",
       "657  3251.6430 -1394.3860 -3463.1084  230.08203  217.76968  5463.2530   \n",
       "664  2879.9160 -1229.9530 -3122.3530  141.35180  212.84225  4930.6720   \n",
       "665  3051.1982 -1305.8528 -3279.6475  122.02283  193.37450  5139.2646   \n",
       "666  3367.7542 -1415.1522 -3596.3857  144.67197  243.71260  5695.8374   \n",
       "707  2498.3262 -1052.4727 -2653.8920  110.90628  186.68768  4281.7220   \n",
       "708  2500.6868 -1047.2345 -2656.4927   93.68875  159.70798  4243.1940   \n",
       "709  3284.6416 -1371.1968 -3414.3423  151.45392  252.93144  5480.6280   \n",
       "761  3310.4907 -1448.4641 -3504.9995  209.27734  254.37192  5639.5757   \n",
       "762  3608.8062 -1581.5908 -3858.2456  237.73800  284.46270  6128.4770   \n",
       "810  3312.9326 -1411.2800 -3540.8320  206.37589  271.44140  5713.6140   \n",
       "847  4069.3052 -1754.0530 -4254.2183  256.76642  278.84686  6848.9440   \n",
       "861  2823.5095 -1205.9938 -3059.5461  134.26843  213.33296  4943.9690   \n",
       "\n",
       "             6          7          8          9  ...        122        123  \\\n",
       "152 -1742.1462 -1933.5850  6134.8670  2059.8123  ...  2552.5480 -474.32940   \n",
       "201 -1666.4711 -1813.6730  5830.6094  1962.3767  ...  2429.6272 -439.15106   \n",
       "284 -1725.6976 -1820.9745  5985.0947  2013.3196  ...  2470.2888 -470.13130   \n",
       "469 -1772.9384 -1923.5074  6199.7950  2082.9504  ...  2581.1968 -515.49690   \n",
       "470 -1941.1052 -2126.2073  6714.9062  2247.8354  ...  2828.8767 -578.98880   \n",
       "494 -2291.9287 -2485.9430  7899.7030  2651.6104  ...  3219.7515 -564.68640   \n",
       "657 -1921.9489 -2112.7670  6662.2188  2243.1538  ...  2744.6404 -462.93610   \n",
       "664 -1748.3600 -1925.1099  6051.9610  2091.0020  ...  2524.9436 -509.46540   \n",
       "665 -1826.1930 -2049.3958  6305.3945  2183.4620  ...  2658.9524 -549.69130   \n",
       "666 -2012.0200 -2226.8752  6994.3135  2406.5762  ...  2922.9407 -602.88360   \n",
       "707 -1544.8362 -1661.8435  5272.6570  1784.1447  ...  2154.5686 -421.37674   \n",
       "708 -1514.3646 -1688.7804  5225.9727  1771.8201  ...  2178.6033 -443.71045   \n",
       "709 -1964.4943 -2176.6072  6698.5293  2268.5947  ...  2801.8540 -573.87550   \n",
       "761 -1937.9694 -2135.6604  6865.8410  2302.3380  ...  2791.3323 -429.82425   \n",
       "762 -2109.9106 -2314.5550  7428.4893  2504.6475  ...  3053.1516 -490.29477   \n",
       "810 -1974.0682 -2161.9531  6949.9170  2359.5370  ...  2851.3274 -450.25323   \n",
       "847 -2382.5837 -2604.7615  8368.1380  2818.7363  ...  3391.4788 -549.24050   \n",
       "861 -1753.3990 -1877.6344  6086.7715  2017.0862  ...  2552.5042 -459.96432   \n",
       "\n",
       "           124        125        126         127  gender  target  cat_id  \\\n",
       "152 -2933.9365  3395.8880 -6107.7456 -1061.96420       X     0.0    109A   \n",
       "201 -2776.0312  3213.3528 -5826.5090 -1019.60443       X     0.0    109A   \n",
       "284 -2825.3770  3296.9670 -5967.8623 -1079.46000       X     0.0    109A   \n",
       "469 -2954.4731  3453.4902 -6172.2075 -1075.68760       X     0.0    109A   \n",
       "470 -3247.7790  3778.4870 -6727.5615 -1191.70600       X     0.0    109A   \n",
       "494 -3733.3735  4508.9165 -8047.7256 -1539.71840       F    16.0    108A   \n",
       "657 -3175.2788  3814.7240 -6818.2993 -1289.64870       F    16.0    108A   \n",
       "664 -2921.8657  3454.4592 -6052.8047 -1120.52040       X     7.0    037A   \n",
       "665 -3071.2742  3649.5955 -6375.6600 -1163.83980       X     7.0    037A   \n",
       "666 -3367.2234  3993.3862 -7069.6455 -1335.39890       X     7.0    037A   \n",
       "707 -2483.4302  2984.2153 -5302.4473  -986.29803       X     7.0    037A   \n",
       "708 -2491.8884  2979.0862 -5240.8800  -944.70320       X     7.0    037A   \n",
       "709 -3170.0178  3905.7253 -6786.7793 -1293.54830       X     7.0    037A   \n",
       "761 -3263.4653  3877.7256 -6970.0034 -1344.60670       F    16.0    108A   \n",
       "762 -3579.6978  4251.9960 -7558.4863 -1451.14070       F    16.0    108A   \n",
       "810 -3287.7632  3861.2432 -7106.4634 -1344.08020       F    16.0    108A   \n",
       "847 -3919.2540  4713.3690 -8497.2140 -1590.58420       F    16.0    108A   \n",
       "861 -2875.1280  3367.5002 -6091.3430 -1054.48690       X     0.0    109A   \n",
       "\n",
       "     age_group  \n",
       "152     kitten  \n",
       "201     kitten  \n",
       "284     kitten  \n",
       "469     kitten  \n",
       "470     kitten  \n",
       "494     senior  \n",
       "657     senior  \n",
       "664      adult  \n",
       "665      adult  \n",
       "666      adult  \n",
       "707      adult  \n",
       "708      adult  \n",
       "709      adult  \n",
       "761     senior  \n",
       "762     senior  \n",
       "810     senior  \n",
       "847     senior  \n",
       "861     kitten  \n",
       "\n",
       "[18 rows x 132 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6002bc10-c5f0-4466-a54c-61ec3fab53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "dataframe['label'] = label_encoder.fit_transform(dataframe['age_group'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c583a97a-299e-4279-838f-4524bdd40386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>gender</th>\n",
       "      <th>target</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>age_group</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3253.6790</td>\n",
       "      <td>-1300.0604</td>\n",
       "      <td>-3428.6190</td>\n",
       "      <td>178.22336</td>\n",
       "      <td>145.87761</td>\n",
       "      <td>5530.4010</td>\n",
       "      <td>-1929.7223</td>\n",
       "      <td>-2155.6733</td>\n",
       "      <td>6838.9844</td>\n",
       "      <td>2277.8290</td>\n",
       "      <td>...</td>\n",
       "      <td>-530.91520</td>\n",
       "      <td>-3267.7144</td>\n",
       "      <td>3789.5164</td>\n",
       "      <td>-6954.0560</td>\n",
       "      <td>-1200.4550</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>006A</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3338.0847</td>\n",
       "      <td>-1419.9960</td>\n",
       "      <td>-3464.4106</td>\n",
       "      <td>183.58270</td>\n",
       "      <td>311.41168</td>\n",
       "      <td>5724.5674</td>\n",
       "      <td>-1989.8912</td>\n",
       "      <td>-2187.1287</td>\n",
       "      <td>7025.0780</td>\n",
       "      <td>2406.5380</td>\n",
       "      <td>...</td>\n",
       "      <td>-515.08560</td>\n",
       "      <td>-3226.8980</td>\n",
       "      <td>3920.7097</td>\n",
       "      <td>-7107.8330</td>\n",
       "      <td>-1304.0648</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>000A</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3282.3360</td>\n",
       "      <td>-1396.4010</td>\n",
       "      <td>-3533.9820</td>\n",
       "      <td>149.29416</td>\n",
       "      <td>207.89177</td>\n",
       "      <td>5654.8940</td>\n",
       "      <td>-1989.5737</td>\n",
       "      <td>-2193.4783</td>\n",
       "      <td>6968.3830</td>\n",
       "      <td>2366.7522</td>\n",
       "      <td>...</td>\n",
       "      <td>-593.87024</td>\n",
       "      <td>-3310.9148</td>\n",
       "      <td>3889.7998</td>\n",
       "      <td>-7059.0030</td>\n",
       "      <td>-1274.8529</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>044A</td>\n",
       "      <td>kitten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4882.2915</td>\n",
       "      <td>-2161.8300</td>\n",
       "      <td>-5307.8610</td>\n",
       "      <td>168.99500</td>\n",
       "      <td>255.57112</td>\n",
       "      <td>8415.0170</td>\n",
       "      <td>-2979.1380</td>\n",
       "      <td>-3213.3972</td>\n",
       "      <td>10388.6070</td>\n",
       "      <td>3472.3523</td>\n",
       "      <td>...</td>\n",
       "      <td>-883.19380</td>\n",
       "      <td>-4949.7915</td>\n",
       "      <td>5769.6240</td>\n",
       "      <td>-10496.9030</td>\n",
       "      <td>-2006.7511</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>014B</td>\n",
       "      <td>kitten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3503.6260</td>\n",
       "      <td>-1458.7937</td>\n",
       "      <td>-3623.8113</td>\n",
       "      <td>196.71686</td>\n",
       "      <td>237.97202</td>\n",
       "      <td>5886.2270</td>\n",
       "      <td>-2068.3577</td>\n",
       "      <td>-2297.6812</td>\n",
       "      <td>7219.8496</td>\n",
       "      <td>2454.4438</td>\n",
       "      <td>...</td>\n",
       "      <td>-546.66240</td>\n",
       "      <td>-3363.1080</td>\n",
       "      <td>4081.6120</td>\n",
       "      <td>-7353.6616</td>\n",
       "      <td>-1369.3765</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>000A</td>\n",
       "      <td>adult</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5  \\\n",
       "0  3253.6790 -1300.0604 -3428.6190  178.22336  145.87761  5530.4010   \n",
       "1  3338.0847 -1419.9960 -3464.4106  183.58270  311.41168  5724.5674   \n",
       "2  3282.3360 -1396.4010 -3533.9820  149.29416  207.89177  5654.8940   \n",
       "3  4882.2915 -2161.8300 -5307.8610  168.99500  255.57112  8415.0170   \n",
       "4  3503.6260 -1458.7937 -3623.8113  196.71686  237.97202  5886.2270   \n",
       "\n",
       "           6          7           8          9  ...        123        124  \\\n",
       "0 -1929.7223 -2155.6733   6838.9844  2277.8290  ... -530.91520 -3267.7144   \n",
       "1 -1989.8912 -2187.1287   7025.0780  2406.5380  ... -515.08560 -3226.8980   \n",
       "2 -1989.5737 -2193.4783   6968.3830  2366.7522  ... -593.87024 -3310.9148   \n",
       "3 -2979.1380 -3213.3972  10388.6070  3472.3523  ... -883.19380 -4949.7915   \n",
       "4 -2068.3577 -2297.6812   7219.8496  2454.4438  ... -546.66240 -3363.1080   \n",
       "\n",
       "         125         126        127  gender  target  cat_id  age_group  label  \n",
       "0  3789.5164  -6954.0560 -1200.4550       M     2.0    006A      adult      0  \n",
       "1  3920.7097  -7107.8330 -1304.0648       F     5.0    000A      adult      0  \n",
       "2  3889.7998  -7059.0030 -1274.8529       X     0.0    044A     kitten      1  \n",
       "3  5769.6240 -10496.9030 -2006.7511       X     0.0    014B     kitten      1  \n",
       "4  4081.6120  -7353.6616 -1369.3765       F     5.0    000A      adult      0  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7acdc-98df-4117-8a0e-6819f0beedce",
   "metadata": {},
   "source": [
    "## save embeddings and labels from demo set to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6820eab6-4253-4efd-9faa-8d55fa729cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved demo_sample_0.csv\n",
      "Saved demo_sample_1.csv\n",
      "Saved demo_sample_2.csv\n",
      "Saved demo_sample_3.csv\n",
      "Saved demo_sample_4.csv\n",
      "Saved demo_sample_5.csv\n",
      "Saved demo_sample_6.csv\n",
      "Saved demo_sample_7.csv\n",
      "Saved demo_sample_8.csv\n",
      "Saved demo_sample_9.csv\n",
      "Saved demo_sample_10.csv\n",
      "Saved demo_sample_11.csv\n",
      "Saved demo_sample_12.csv\n",
      "Saved demo_sample_13.csv\n",
      "Saved demo_sample_14.csv\n",
      "Saved demo_sample_15.csv\n",
      "Saved demo_sample_16.csv\n",
      "Saved demo_sample_17.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure the target labels in demo_samples are encoded using the same LabelEncoder\n",
    "demo_samples = demo_samples.copy()  # Avoid SettingWithCopyWarning\n",
    "demo_samples['label'] = label_encoder.transform(demo_samples['age_group'].values)\n",
    "\n",
    "# Extract features and labels from demo_samples\n",
    "features = demo_samples.iloc[:, :-5].values  # all columns except the last five\n",
    "labels = demo_samples['label'].values\n",
    "\n",
    "# Save each row to a separate CSV file\n",
    "for i, (feature_row, label) in enumerate(zip(features, labels)):\n",
    "    # Create a DataFrame for the current row\n",
    "    row_df = pd.DataFrame([np.append(feature_row, label)])\n",
    "    \n",
    "    # Create a filename\n",
    "    filename = f'demo_sample_{i}.csv'\n",
    "    \n",
    "    # Save to CSV file\n",
    "    row_df.to_csv(filename, index=False, header=False)\n",
    "    \n",
    "    print(f'Saved {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3c6e2bf0-5f8d-481e-b29a-234800b08242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined_demo_samples.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure the target labels are encoded as 0 for kitten and 1 for senior\n",
    "demo_samples = demo_samples.copy()  # Avoid SettingWithCopyWarning\n",
    "demo_samples['label'] = label_encoder.transform(demo_samples['age_group'].values)\n",
    "\n",
    "# Extract features and labels\n",
    "features = demo_samples.iloc[:, :-5].values\n",
    "labels = demo_samples['label'].values\n",
    "\n",
    "# Combine features and labels into a single DataFrame\n",
    "combined_data = np.hstack((features, labels.reshape(-1, 1)))\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Create a filename for the combined CSV file\n",
    "combined_filename = 'combined_demo_samples.csv'\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "combined_df.to_csv(combined_filename, index=False, header=False)\n",
    "\n",
    "print(f'Saved {combined_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "32faed01-7376-4bbd-a8e6-c257fccd8c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>count</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>026B</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>019B</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>110A</td>\n",
       "      <td>1</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>100A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>090A</td>\n",
       "      <td>1</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>115A</td>\n",
       "      <td>1</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>091A</td>\n",
       "      <td>1</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>024A</td>\n",
       "      <td>1</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>073A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>066A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>096A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>004A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>048A</td>\n",
       "      <td>1</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>043A</td>\n",
       "      <td>1</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>026C</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>041A</td>\n",
       "      <td>1</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>092A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>049A</td>\n",
       "      <td>1</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>076A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>088A</td>\n",
       "      <td>1</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>069A</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>032A</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>011A</td>\n",
       "      <td>2</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>038A</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>102A</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>025B</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>061A</td>\n",
       "      <td>2</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>087A</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>093A</td>\n",
       "      <td>2</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>054A</td>\n",
       "      <td>2</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>018A</td>\n",
       "      <td>2</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>012A</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>058A</td>\n",
       "      <td>3</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>064A</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>006A</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>056A</td>\n",
       "      <td>3</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>014A</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>113A</td>\n",
       "      <td>3</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>060A</td>\n",
       "      <td>3</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>003A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>062A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>052A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>105A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>035A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>026A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>104A</td>\n",
       "      <td>4</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>009A</td>\n",
       "      <td>4</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>023B</td>\n",
       "      <td>5</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>034A</td>\n",
       "      <td>5</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>021A</td>\n",
       "      <td>5</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>075A</td>\n",
       "      <td>5</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>044A</td>\n",
       "      <td>5</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>070A</td>\n",
       "      <td>5</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>025C</td>\n",
       "      <td>5</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>108A</td>\n",
       "      <td>6</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>037A</td>\n",
       "      <td>6</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>007A</td>\n",
       "      <td>6</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>008A</td>\n",
       "      <td>6</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>023A</td>\n",
       "      <td>6</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>109A</td>\n",
       "      <td>6</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>053A</td>\n",
       "      <td>6</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>031A</td>\n",
       "      <td>7</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>099A</td>\n",
       "      <td>7</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>050A</td>\n",
       "      <td>7</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>027A</td>\n",
       "      <td>7</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>117A</td>\n",
       "      <td>7</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>095A</td>\n",
       "      <td>8</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>013B</td>\n",
       "      <td>8</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>010A</td>\n",
       "      <td>8</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>094A</td>\n",
       "      <td>8</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>022A</td>\n",
       "      <td>9</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>045A</td>\n",
       "      <td>9</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>051B</td>\n",
       "      <td>9</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>072A</td>\n",
       "      <td>9</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>015A</td>\n",
       "      <td>9</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>065A</td>\n",
       "      <td>9</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>033A</td>\n",
       "      <td>9</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>016A</td>\n",
       "      <td>10</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>071A</td>\n",
       "      <td>10</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>040A</td>\n",
       "      <td>10</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>014B</td>\n",
       "      <td>10</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>005A</td>\n",
       "      <td>10</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>025A</td>\n",
       "      <td>11</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>068A</td>\n",
       "      <td>11</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>063A</td>\n",
       "      <td>11</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>036A</td>\n",
       "      <td>11</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>051A</td>\n",
       "      <td>12</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>116A</td>\n",
       "      <td>12</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>039A</td>\n",
       "      <td>12</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>111A</td>\n",
       "      <td>13</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>002A</td>\n",
       "      <td>13</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>028A</td>\n",
       "      <td>13</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>097B</td>\n",
       "      <td>14</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>059A</td>\n",
       "      <td>14</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>042A</td>\n",
       "      <td>14</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>001A</td>\n",
       "      <td>14</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>106A</td>\n",
       "      <td>14</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101A</td>\n",
       "      <td>15</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>097A</td>\n",
       "      <td>16</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>029A</td>\n",
       "      <td>17</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>019A</td>\n",
       "      <td>17</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>067A</td>\n",
       "      <td>19</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000B</td>\n",
       "      <td>19</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>055A</td>\n",
       "      <td>20</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>020A</td>\n",
       "      <td>23</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>074A</td>\n",
       "      <td>25</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>057A</td>\n",
       "      <td>27</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>047A</td>\n",
       "      <td>28</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002B</td>\n",
       "      <td>32</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103A</td>\n",
       "      <td>33</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000A</td>\n",
       "      <td>39</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>046A</td>\n",
       "      <td>63</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_id  count age_group\n",
       "111   026B      1     adult\n",
       "92    019B      1     adult\n",
       "93    110A      1    kitten\n",
       "94    100A      1     adult\n",
       "95    090A      1    senior\n",
       "96    115A      1    kitten\n",
       "97    091A      1    senior\n",
       "98    024A      1    senior\n",
       "99    073A      1     adult\n",
       "100   066A      1     adult\n",
       "110   096A      1     adult\n",
       "102   004A      1     adult\n",
       "103   048A      1    kitten\n",
       "104   043A      1    kitten\n",
       "105   026C      1     adult\n",
       "106   041A      1    kitten\n",
       "107   092A      1     adult\n",
       "108   049A      1    kitten\n",
       "109   076A      1     adult\n",
       "101   088A      1     adult\n",
       "81    069A      2     adult\n",
       "82    032A      2     adult\n",
       "84    011A      2    senior\n",
       "85    038A      2     adult\n",
       "83    102A      2     adult\n",
       "87    025B      2     adult\n",
       "88    061A      2    senior\n",
       "86    087A      2     adult\n",
       "89    093A      2    senior\n",
       "90    054A      2    senior\n",
       "91    018A      2     adult\n",
       "73    012A      3     adult\n",
       "74    058A      3    senior\n",
       "75    064A      3     adult\n",
       "77    006A      3     adult\n",
       "78    056A      3    senior\n",
       "79    014A      3     adult\n",
       "80    113A      3    senior\n",
       "76    060A      3    senior\n",
       "66    003A      4     adult\n",
       "67    062A      4     adult\n",
       "68    052A      4     adult\n",
       "65    105A      4     adult\n",
       "71    035A      4     adult\n",
       "72    026A      4     adult\n",
       "69    104A      4    senior\n",
       "70    009A      4     adult\n",
       "64    023B      5     adult\n",
       "63    034A      5     adult\n",
       "62    021A      5     adult\n",
       "61    075A      5     adult\n",
       "60    044A      5    kitten\n",
       "59    070A      5     adult\n",
       "58    025C      5    senior\n",
       "56    108A      6    senior\n",
       "57    037A      6     adult\n",
       "55    007A      6     adult\n",
       "53    008A      6    senior\n",
       "52    023A      6     adult\n",
       "51    109A      6    kitten\n",
       "54    053A      6    senior\n",
       "50    031A      7     adult\n",
       "49    099A      7     adult\n",
       "48    050A      7    kitten\n",
       "47    027A      7     adult\n",
       "46    117A      7    senior\n",
       "45    095A      8     adult\n",
       "44    013B      8     adult\n",
       "43    010A      8     adult\n",
       "42    094A      8    senior\n",
       "35    022A      9     adult\n",
       "36    045A      9    kitten\n",
       "37    051B      9    senior\n",
       "41    072A      9     adult\n",
       "39    015A      9    senior\n",
       "40    065A      9     adult\n",
       "38    033A      9     adult\n",
       "34    016A     10    senior\n",
       "33    071A     10     adult\n",
       "32    040A     10    kitten\n",
       "31    014B     10    kitten\n",
       "30    005A     10     adult\n",
       "27    025A     11    senior\n",
       "26    068A     11     adult\n",
       "29    063A     11     adult\n",
       "28    036A     11     adult\n",
       "25    051A     12    senior\n",
       "24    116A     12    senior\n",
       "23    039A     12    senior\n",
       "22    111A     13    kitten\n",
       "21    002A     13     adult\n",
       "20    028A     13    senior\n",
       "19    097B     14     adult\n",
       "18    059A     14    senior\n",
       "17    042A     14    kitten\n",
       "16    001A     14    senior\n",
       "15    106A     14    senior\n",
       "14    101A     15    senior\n",
       "13    097A     16    senior\n",
       "11    029A     17     adult\n",
       "12    019A     17     adult\n",
       "10    067A     19     adult\n",
       "9     000B     19     adult\n",
       "8     055A     20    senior\n",
       "7     020A     23     adult\n",
       "6     074A     25     adult\n",
       "5     057A     27    senior\n",
       "4     047A     28    kitten\n",
       "3     002B     32     adult\n",
       "2     103A     33    senior\n",
       "1     000A     39     adult\n",
       "0     046A     63    kitten"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each cat_id\n",
    "cat_id_counts = dataframe['cat_id'].value_counts().reset_index()\n",
    "cat_id_counts.columns = ['cat_id', 'count']\n",
    "\n",
    "# Merge with the age group information\n",
    "age_group_info = dataframe[['cat_id', 'age_group']].drop_duplicates()\n",
    "cat_id_counts_with_age_group = cat_id_counts.merge(age_group_info, on='cat_id')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the result\n",
    "cat_id_counts_with_age_group.sort_values(by='count', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15df483-5d53-4d6f-8fc4-dd5fa0ba2f95",
   "metadata": {},
   "source": [
    "### samples for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b769c85b-b581-4525-994d-6be79017b9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding: {'adult': 0, 'kitten': 1, 'senior': 2}\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels for the full dataset\n",
    "X = dataframe.iloc[:, :-5].values  # all columns except the last five\n",
    "y = dataframe['label'].values\n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler_full = StandardScaler().fit(X)\n",
    "X_scaled = scaler_full.transform(X)\n",
    "\n",
    "# Encode the labels using one-hot encoding\n",
    "y_encoded = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Select specific cat_id values for demonstration samples\n",
    "kitten_cat_id = \"109A\"\n",
    "adult_cat_id = \"037A\"\n",
    "senior_cat_id = \"108A\"\n",
    "\n",
    "# Select all rows corresponding to the sampled cat_id values\n",
    "demo_samples = dataframe[(dataframe['cat_id'] == kitten_cat_id) | \n",
    "                         (dataframe['cat_id'] == senior_cat_id) | \n",
    "                         (dataframe['cat_id'] == adult_cat_id)].index\n",
    "\n",
    "# Convert dataframe indices to positional indices\n",
    "demo_sample_positions = dataframe.index.get_indexer(demo_samples)\n",
    "\n",
    "# Separate demonstration samples using positional indices\n",
    "X_demo = X_scaled[demo_sample_positions]\n",
    "y_demo = y_encoded[demo_sample_positions]\n",
    "\n",
    "# Remove demonstration samples from the training set\n",
    "X_train_full = np.delete(X_scaled, demo_sample_positions, axis=0)\n",
    "y_train_full = np.delete(y_encoded, demo_sample_positions, axis=0)\n",
    "\n",
    "# Print label encoding for verification\n",
    "print(\"Label encoding:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe72ce-7c90-4685-ae78-f8da55aa9024",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "520d9913-55d4-46e1-aecd-9e32e89052fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',  \n",
    "    min_delta=0.001, \n",
    "    patience=30,  \n",
    "    verbose=1,  \n",
    "    restore_best_weights=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5d36fca0-3968-4135-a57b-e14d61162ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.0772 - accuracy: 0.4897\n",
      "Epoch 2/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7969 - accuracy: 0.5985\n",
      "Epoch 3/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7644 - accuracy: 0.6159\n",
      "Epoch 4/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.6442\n",
      "Epoch 5/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.6398\n",
      "Epoch 6/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6866\n",
      "Epoch 7/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6529\n",
      "Epoch 8/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6953\n",
      "Epoch 9/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6921\n",
      "Epoch 10/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6260 - accuracy: 0.7149\n",
      "Epoch 11/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.6975\n",
      "Epoch 12/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7062\n",
      "Epoch 13/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7280\n",
      "Epoch 14/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7334\n",
      "Epoch 15/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7247\n",
      "Epoch 16/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7312\n",
      "Epoch 17/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7552\n",
      "Epoch 18/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7628\n",
      "Epoch 19/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7584\n",
      "Epoch 20/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7476\n",
      "Epoch 21/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7573\n",
      "Epoch 22/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7813\n",
      "Epoch 23/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7650\n",
      "Epoch 24/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7595\n",
      "Epoch 25/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7704\n",
      "Epoch 26/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7758\n",
      "Epoch 27/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7748\n",
      "Epoch 28/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7835\n",
      "Epoch 29/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7791\n",
      "Epoch 30/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7845\n",
      "Epoch 31/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7933\n",
      "Epoch 32/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7878\n",
      "Epoch 33/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7976\n",
      "Epoch 34/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7715\n",
      "Epoch 35/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8009\n",
      "Epoch 36/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8030\n",
      "Epoch 37/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7976\n",
      "Epoch 38/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8063\n",
      "Epoch 39/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8074\n",
      "Epoch 40/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8074\n",
      "Epoch 41/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8118\n",
      "Epoch 42/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8063\n",
      "Epoch 43/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8161\n",
      "Epoch 44/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.7922\n",
      "Epoch 45/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8292\n",
      "Epoch 46/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8107\n",
      "Epoch 47/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8128\n",
      "Epoch 48/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8335\n",
      "Epoch 49/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8346\n",
      "Epoch 50/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8335\n",
      "Epoch 51/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8335\n",
      "Epoch 52/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8128\n",
      "Epoch 53/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8172\n",
      "Epoch 54/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8313\n",
      "Epoch 55/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8335\n",
      "Epoch 56/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8237\n",
      "Epoch 57/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8248\n",
      "Epoch 58/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8237\n",
      "Epoch 59/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8292\n",
      "Epoch 60/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3603 - accuracy: 0.8270\n",
      "Epoch 61/1500\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8466\n",
      "Epoch 62/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8237\n",
      "Epoch 63/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8444\n",
      "Epoch 64/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8368\n",
      "Epoch 65/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8313\n",
      "Epoch 66/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8379\n",
      "Epoch 67/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8662\n",
      "Epoch 68/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8520\n",
      "Epoch 69/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8477\n",
      "Epoch 70/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8477\n",
      "Epoch 71/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8455\n",
      "Epoch 72/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8498\n",
      "Epoch 73/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8564\n",
      "Epoch 74/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8553\n",
      "Epoch 75/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8357\n",
      "Epoch 76/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8281\n",
      "Epoch 77/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8433\n",
      "Epoch 78/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8640\n",
      "Epoch 79/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8400\n",
      "Epoch 80/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8422\n",
      "Epoch 81/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8607\n",
      "Epoch 82/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8400\n",
      "Epoch 83/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8694\n",
      "Epoch 84/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8542\n",
      "Epoch 85/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.8683\n",
      "Epoch 86/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8477\n",
      "Epoch 87/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8640\n",
      "Epoch 88/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8509\n",
      "Epoch 89/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.8672\n",
      "Epoch 90/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8629\n",
      "Epoch 91/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.8607\n",
      "Epoch 92/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.8770\n",
      "Epoch 93/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.8738\n",
      "Epoch 94/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8596\n",
      "Epoch 95/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8716\n",
      "Epoch 96/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8585\n",
      "Epoch 97/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.8683\n",
      "Epoch 98/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.8694\n",
      "Epoch 99/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.8662\n",
      "Epoch 100/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8694\n",
      "Epoch 101/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8683\n",
      "Epoch 102/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8760\n",
      "Epoch 103/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8575\n",
      "Epoch 104/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8879\n",
      "Epoch 105/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.8923\n",
      "Epoch 106/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8770\n",
      "Epoch 107/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.8945\n",
      "Epoch 108/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8705\n",
      "Epoch 109/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.8792\n",
      "Epoch 110/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8662\n",
      "Epoch 111/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8792\n",
      "Epoch 112/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.8868\n",
      "Epoch 113/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8955\n",
      "Epoch 114/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.8857\n",
      "Epoch 115/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8934\n",
      "Epoch 116/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8857\n",
      "Epoch 117/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.8868\n",
      "Epoch 118/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8857\n",
      "Epoch 119/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.8836\n",
      "Epoch 120/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9064\n",
      "Epoch 121/1500\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8912\n",
      "Epoch 122/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8879\n",
      "Epoch 123/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.8857\n",
      "Epoch 124/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.8955\n",
      "Epoch 125/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9021\n",
      "Epoch 126/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.8955\n",
      "Epoch 127/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8857\n",
      "Epoch 128/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9075\n",
      "Epoch 129/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8879\n",
      "Epoch 130/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.8934\n",
      "Epoch 131/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8945\n",
      "Epoch 132/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.8879\n",
      "Epoch 133/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8836\n",
      "Epoch 134/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.8836\n",
      "Epoch 135/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9151\n",
      "Epoch 136/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.8879\n",
      "Epoch 137/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.8760\n",
      "Epoch 138/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.8966\n",
      "Epoch 139/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9075\n",
      "Epoch 140/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9119\n",
      "Epoch 141/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.9064\n",
      "Epoch 142/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.8923\n",
      "Epoch 143/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.8945\n",
      "Epoch 144/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.8966\n",
      "Epoch 145/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.8999\n",
      "Epoch 146/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.8999\n",
      "Epoch 147/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9184\n",
      "Epoch 148/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.9042\n",
      "Epoch 149/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9260\n",
      "Epoch 150/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.8999\n",
      "Epoch 151/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9206\n",
      "Epoch 152/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9108\n",
      "Epoch 153/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.8988\n",
      "Epoch 154/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.9064\n",
      "Epoch 155/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9086\n",
      "Epoch 156/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9010\n",
      "Epoch 157/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9042\n",
      "Epoch 158/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9140\n",
      "Epoch 159/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9021\n",
      "Epoch 160/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9119\n",
      "Epoch 161/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.8999\n",
      "Epoch 162/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.9097\n",
      "Epoch 163/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9010\n",
      "Epoch 164/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9075\n",
      "Epoch 165/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9053\n",
      "Epoch 166/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.8977\n",
      "Epoch 167/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9162\n",
      "Epoch 168/1500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9162\n",
      "Epoch 169/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9086\n",
      "Epoch 170/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9151\n",
      "Epoch 171/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9032\n",
      "Epoch 172/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.8945\n",
      "Epoch 173/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9162\n",
      "Epoch 174/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9053\n",
      "Epoch 175/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9108\n",
      "Epoch 176/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9097\n",
      "Epoch 177/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9151\n",
      "Epoch 178/1500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9173\n",
      "Epoch 179/1500\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.1447 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 149.\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9206\n",
      "Epoch 179: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define optimizers\n",
    "optimizers = {\n",
    "    'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "}\n",
    "\n",
    "# Compute class weights for the training set\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(np.argmax(y_train_full, axis=1)),\n",
    "    y=np.argmax(y_train_full, axis=1)\n",
    ")\n",
    "weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Full model definition with dynamic number of layers\n",
    "model_full = Sequential()\n",
    "model_full.add(Dense(480, activation='relu', input_shape=(X_train_full.shape[1],)))  # units and input shape from parameters\n",
    "model_full.add(BatchNormalization())\n",
    "model_full.add(Dropout(0.27188281261238406))\n",
    "model_full.add(Dense(3, activation='softmax'))  # for multi-class classification\n",
    "\n",
    "optimizer = optimizers['Adamax']  # optimizer selection\n",
    "\n",
    "# Compile the model for categorical classification\n",
    "model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the full training set\n",
    "history_full = model_full.fit(X_train_full, y_train_full, epochs=1500, batch_size=32,\n",
    "                              verbose=1, callbacks=[early_stopping], class_weight=weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3738341a-6def-4f45-b155-791d8e445ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.6747430249632893, 1: 1.8565656565656565, 2: 1.021111111111111}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class Weights: {weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b2dd55eb-4ac9-4b0e-8c0d-57389ccd94c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'adult', 1: 'kitten', 2: 'senior'}\n"
     ]
    }
   ],
   "source": [
    "# Save the label mapping\n",
    "label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(label_mapping)  # This will print the mapping of labels to encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ccfee396-7e86-4ace-9f84-bdd8d1534073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Set Accuracy: 95.54%\n",
      "Demo Set Accuracy: 88.89%\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Sample 0: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.6903, Kitten: 0.3056, Senior: 0.0041)\n",
      "Sample 1: Predicted=Kitten, Actual=Kitten, Probabilities=(Adult: 0.3642, Kitten: 0.6280, Senior: 0.0078)\n",
      "Sample 2: Predicted=Kitten, Actual=Kitten, Probabilities=(Adult: 0.0061, Kitten: 0.9938, Senior: 0.0001)\n",
      "Sample 3: Predicted=Kitten, Actual=Kitten, Probabilities=(Adult: 0.0340, Kitten: 0.9648, Senior: 0.0012)\n",
      "Sample 4: Predicted=Kitten, Actual=Kitten, Probabilities=(Adult: 0.4167, Kitten: 0.5605, Senior: 0.0228)\n",
      "Sample 5: Predicted=Senior, Actual=Senior, Probabilities=(Adult: 0.1161, Kitten: 0.0028, Senior: 0.8811)\n",
      "Sample 6: Predicted=Senior, Actual=Senior, Probabilities=(Adult: 0.3129, Kitten: 0.0007, Senior: 0.6864)\n",
      "Sample 7: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.9898, Kitten: 0.0002, Senior: 0.0100)\n",
      "Sample 8: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.8689, Kitten: 0.0000, Senior: 0.1311)\n",
      "Sample 9: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.9843, Kitten: 0.0034, Senior: 0.0123)\n",
      "Sample 10: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.9463, Kitten: 0.0423, Senior: 0.0114)\n",
      "Sample 11: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.8354, Kitten: 0.0782, Senior: 0.0864)\n",
      "Sample 12: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.9791, Kitten: 0.0013, Senior: 0.0196)\n",
      "Sample 13: Predicted=Senior, Actual=Senior, Probabilities=(Adult: 0.1492, Kitten: 0.0005, Senior: 0.8503)\n",
      "Sample 14: Predicted=Senior, Actual=Senior, Probabilities=(Adult: 0.0752, Kitten: 0.0000, Senior: 0.9247)\n",
      "Sample 15: Predicted=Senior, Actual=Senior, Probabilities=(Adult: 0.2891, Kitten: 0.0009, Senior: 0.7099)\n",
      "Sample 16: Predicted=Senior, Actual=Senior, Probabilities=(Adult: 0.1049, Kitten: 0.0042, Senior: 0.8908)\n",
      "Sample 17: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.5297, Kitten: 0.4698, Senior: 0.0005)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set to get total accuracy\n",
    "loss, accuracy = model_full.evaluate(X_train_full, y_train_full, verbose=0)\n",
    "print(f\"Total Training Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on the demo set to get accuracy\n",
    "loss, accuracy = model_full.evaluate(X_demo, y_demo, verbose=0)\n",
    "print(f\"Demo Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict probabilities for the demo samples\n",
    "probabilities = model_full.predict(X_demo)\n",
    "\n",
    "# Convert probabilities to class predictions\n",
    "predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Define the label mapping if not already defined\n",
    "label_mapping = {0: 'Adult', 1: 'Kitten', 2: 'Senior'}\n",
    "\n",
    "# Map predictions and actual labels to \"Kitten\", \"Adult\", or \"Senior\" classes\n",
    "mapped_predictions = [label_mapping[pred] for pred in predictions]\n",
    "mapped_actual_labels = [label_mapping[np.argmax(label)] for label in y_demo]\n",
    "\n",
    "# Print out the probabilities along with actual labels and predictions\n",
    "for i in range(len(probabilities)):\n",
    "    prob_str = ', '.join([f'{label_mapping[j]}: {prob:.4f}' for j, prob in enumerate(probabilities[i])])\n",
    "    print(f\"Sample {i}: Predicted={mapped_predictions[i]}, Actual={mapped_actual_labels[i]}, Probabilities=({prob_str})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "452ed526-b91a-4f96-b611-5f7956231051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class Adult: 100.00%\n",
      "Accuracy for class Kitten: 66.67%\n",
      "Accuracy for class Senior: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix([np.argmax(label) for label in y_demo], predictions)\n",
    "\n",
    "# Calculate the accuracy per class\n",
    "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "# Map the accuracies to class labels\n",
    "class_accuracy_map = {label_mapping[i]: class_accuracies[i] for i in range(len(class_accuracies))}\n",
    "\n",
    "# Print the accuracy per class\n",
    "for class_label, accuracy in class_accuracy_map.items():\n",
    "    print(f\"Accuracy for class {class_label}: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b41d719d-8947-4bda-aaab-1003a703565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Set Accuracy: 95.54%\n",
      "Demo Set Accuracy: 88.89%\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Sample 0: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.6903, Kitten: 0.3056, Senior: 0.0041)\n",
      "Sample 1: Predicted=Kitten, Actual=Adult, Probabilities=(Adult: 0.3642, Kitten: 0.6280, Senior: 0.0078)\n",
      "Sample 2: Predicted=Kitten, Actual=Adult, Probabilities=(Adult: 0.0061, Kitten: 0.9938, Senior: 0.0001)\n",
      "Sample 3: Predicted=Kitten, Actual=Adult, Probabilities=(Adult: 0.0340, Kitten: 0.9648, Senior: 0.0012)\n",
      "Sample 4: Predicted=Kitten, Actual=Adult, Probabilities=(Adult: 0.4167, Kitten: 0.5605, Senior: 0.0228)\n",
      "Sample 5: Predicted=Senior, Actual=Adult, Probabilities=(Adult: 0.1161, Kitten: 0.0028, Senior: 0.8811)\n",
      "Sample 6: Predicted=Senior, Actual=Adult, Probabilities=(Adult: 0.3129, Kitten: 0.0007, Senior: 0.6864)\n",
      "Sample 7: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.9898, Kitten: 0.0002, Senior: 0.0100)\n",
      "Sample 8: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.8689, Kitten: 0.0000, Senior: 0.1311)\n",
      "Sample 9: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.9843, Kitten: 0.0034, Senior: 0.0123)\n",
      "Sample 10: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.9463, Kitten: 0.0423, Senior: 0.0114)\n",
      "Sample 11: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.8354, Kitten: 0.0782, Senior: 0.0864)\n",
      "Sample 12: Predicted=Adult, Actual=Kitten, Probabilities=(Adult: 0.9791, Kitten: 0.0013, Senior: 0.0196)\n",
      "Sample 13: Predicted=Senior, Actual=Adult, Probabilities=(Adult: 0.1492, Kitten: 0.0005, Senior: 0.8503)\n",
      "Sample 14: Predicted=Senior, Actual=Adult, Probabilities=(Adult: 0.0752, Kitten: 0.0000, Senior: 0.9247)\n",
      "Sample 15: Predicted=Senior, Actual=Adult, Probabilities=(Adult: 0.2891, Kitten: 0.0009, Senior: 0.7099)\n",
      "Sample 16: Predicted=Senior, Actual=Adult, Probabilities=(Adult: 0.1049, Kitten: 0.0042, Senior: 0.8908)\n",
      "Sample 17: Predicted=Adult, Actual=Adult, Probabilities=(Adult: 0.5297, Kitten: 0.4698, Senior: 0.0005)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set to get total accuracy\n",
    "loss, accuracy = model_full.evaluate(X_train_full, y_train_full, verbose=0)\n",
    "print(f\"Total Training Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on the demo set to get accuracy\n",
    "loss, accuracy = model_full.evaluate(X_demo, y_demo, verbose=0)\n",
    "print(f\"Demo Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict probabilities for the demo samples\n",
    "probabilities = model_full.predict(X_demo)\n",
    "\n",
    "# Convert probabilities to class predictions\n",
    "predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Map predictions and actual labels to \"Kitten\", \"Adult\", or \"Senior\" classes\n",
    "mapped_predictions = [label_mapping[pred] for pred in predictions]\n",
    "mapped_actual_labels = [label_mapping[np.argmax(label)] for label in y_demo_encoded]\n",
    "\n",
    "# Print out the probabilities along with actual labels and predictions\n",
    "for i in range(len(probabilities)):\n",
    "    class_probabilities = \", \".join([f\"{label_mapping[j]}: {prob:.4f}\" for j, prob in enumerate(probabilities[i])])\n",
    "    print(f\"Sample {i}: Predicted={mapped_predictions[i]}, Actual={mapped_actual_labels[i]}, Probabilities=({class_probabilities})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bf63c-14a7-4474-b195-3c12a4ee3813",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "af34fc89-a102-40da-96c9-770f30406f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the StandardScaler\n",
    "joblib.dump(scaler_full, 'scaler_full.pkl')\n",
    "\n",
    "# Save the trained model\n",
    "model_full.save('cat_age_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
